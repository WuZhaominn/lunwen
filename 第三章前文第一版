\chapter{基于表示空间定向偏移的联邦遗忘算法}
车联网在联邦学习（Federated Learning, FL）这一分布式机器学习范式的赋能下，使车辆能够在本地保留其私有数据的同时，通过协作方式共同训练全局模型~\cite{ref1}。该协同学习模式在隐私保护的前提下实现了车辆间的高效知识共享，从而提升了整体交通系统的运行效率与智能化水平~\cite{ref2}。然而，基于联邦学习的车联网体系普遍缺乏有效的数据撤销机制，无法从已训练的全局模型中移除特定训练数据所产生的影响，这在一定程度上可能违反车辆用户所享有的“被遗忘权”。为解决上述问题，联邦遗忘（Federated Unlearning, FU）作为一种新兴技术应运而生，其目标是在不重新训练整个模型的前提下，从全局模型中消除特定车辆或特定数据子集的影响~\cite{ref3}。通过引入这一可选择退出（opt-out）机制，FU 进一步增强了车辆对其私有信息的控制能力，并为分布式知识共享过程中的条件化参与与隐私合规性提供了有力支撑。

联邦遗忘（FU）是一种机器遗忘（MU）技术，旨在以分布式的方式消除待遗忘数据对全局模型的影响。令 $\mathcal{D}_f = \cup_{i \in U_f} \mathcal{D}_i^f$ 表示所有目标车辆中待遗忘数据集的完整集合。若存在一个联邦遗忘算法 $\mathcal{F U}(\mathcal{F}(\omega^o), U_f, \mathcal{D}, \mathcal{D}_t)$，其输出的更新后全局模型 $\mathcal{F}(\boldsymbol{\omega}^{\circ\prime})$能够满足定义 1，则认为该联邦遗忘过程是完美执行的。在联邦学习（FL）中满足定义 1，可确保更新后的全局模型 $\mathcal{F}(\boldsymbol{\omega}^{\circ\prime})$ 在被遗忘数据集 $\mathcal{D}_f$ 上的表现类似于其在未见数据上的表现，同时在非成员数据集 $\mathcal{D}_t$ 上保持与原始模型 $\mathcal{F}(\omega^o)$ 相当的性能。

联邦遗忘旨在实现以下目标：(1) 有效遗忘。$\mathcal{FU}\big(\mathcal{F}(\boldsymbol{\omega}^\circ), \mathcal{U}_f, \mathcal{D}, \mathcal{D}_t\big)$ 应尽可能彻底地消除被遗忘数据 $\mathcal{D}_f$ 对原始模型 $\mathcal{F}(\boldsymbol{\omega}^\circ)$ 的影响。(2) 具有竞争力的全局模型预测性能。由 $\mathcal{FU}\big(\mathcal{F}(\boldsymbol{\omega}^\circ), \mathcal{U}_f, \mathcal{D}, \mathcal{D}_t\big)$ 生成的模型 $\mathcal{F}(\boldsymbol{\omega}^{\circ\prime})$，在非成员数据集 $\mathcal{D}_t$ 上应当与原始模型 $\mathcal{F}(\boldsymbol{\omega}^\circ)$ 保持尽可能小的性能差距。(3) 高效遗忘。$\mathcal{FU}\big(\mathcal{F}(\boldsymbol{\omega}^\circ), \mathcal{U}_f, \mathcal{D}, \mathcal{D}_t\big)$ 的计算开销应显著低于重新训练模型 $\mathcal{F}(\tilde{\boldsymbol{\omega}})$ 的代价。

为了从全局模型中移除车辆指定训练数据的影响，一种方法是仅利用剩余数据从头开始重新训练一个新的全局模型。然而，该方法在时间和计算成本上均十分高昂。因此，现有 FU 方法的核心目标是在较低成本下获得与完全重训练效果相当的更新全局模型。根据目标车辆在遗忘过程中的参与程度以及遗忘操作是否需要其他参与方协作，这些方法可分为被动式 FU 和主动式 FU。如图\ref{fig:fl-sys3} 所示，被动式 FU 通过使用所有参与车辆的剩余数据执行额外的训练步骤，以加速从头重训练或对全局模型进行校准。相比之下，主动式 FU 允许目标车辆基于其待遗忘数据对接收到的全局模型进行本地调整，生成遗忘后的本地模型，并由服务器对这些模型进行聚合以得到新的全局模型。

尽管现有 FU 方法在遗忘效率方面相较于完全重训练具有明显优势，但在 IoV 场景下的实际部署可行性与非遗忘数据的性能保持（Utility Preservation）方面仍面临严峻挑战。（1）被动式 FU 方法通常由于需要所有既有参与车辆执行耗时的重训练步骤，以及为重构全局模型而引入额外的聚合轮次，而在实践中难以部署，如图\ref{fig:fl-sys3}(a) 所示。尽管该类方法能够保证全局模型的高可用性，但在车辆数量众多且高度动态的 IoV 环境中，其可行性受到显著限制，主要原因在于难以召回所有参与方。此外，基于全部剩余数据的重训练还会带来额外的计算与通信开销。上述耗时过程以及对其他车辆参与的依赖，使得在 IoV 中实现实时数据撤销服务面临较大障碍。值得注意的是，其余车辆通常缺乏动机投入计算资源以协助目标车辆完成数据遗忘。（2）主动式 FU 方法由于缺乏在全局模型参数空间中明确的优化目标，往往在遗忘有效性方面存在不足，甚至可能引发灾难性遗忘，如图\ref{fig:fl-sys3}(b) 所示。这类方法通常采用梯度上升（Gradient Ascent）等策略最大化待遗忘数据的损失，对全局模型的全部参数进行统一优化，以尽可能消除待遗忘数据对全局模型的影响。然而，由于全局模型本身的聚合特性以及遗忘程度难以精确界定，这些方法难以有效解耦待遗忘数据的影响，可能过度削弱未遗忘数据的贡献，从而导致灾难性遗忘现象。灾难性遗忘会显著降低全局模型在未遗忘数据上的预测性能，而在 IoV 场景中，预测准确性和模型可靠性对于保障安全且良好的驾驶体验至关重要，因此其后果尤为严重。一些方法通过预定义阈值来约束遗忘程度，试图使全局模型在待遗忘数据上的表现与重训练模型保持一致~\cite{9}。然而，由于难以合理设定阈值，或在缺乏先验信息的情况下直接匹配完全重训练模型的性能，这类方法可能削弱遗忘效果，并导致待遗忘数据的残留记忆。

综上所述，一种适用于 IoV 的高效 FU 方法，应当在无需其他车辆参与且避免额外耗时重训练的前提下，有效消除待遗忘数据对全局模型的影响，同时尽量降低对未遗忘数据预测性能的损害。


\begin{figure}[htb]
    \centering
    \includegraphics[scale=0.3]{picture/ProblemDescriptionsOnFederatedNnlearning.png}
    \caption{
        关于联邦遗忘的问题描述
    }
    \label{fig:fl-sys3}
\end{figure}


\section{动机与设计思路}
为在有效消除待遗忘数据影响的同时尽量降低对全局模型性能的负面影响，我们提出了一种面向 IoV 的实用型联邦遗忘框架——VeriFed-UL。VeriFed-UL 采用主动式 FU 范式，使目标车辆能够通过在原始全局模型上执行定制化的本地遗忘过程，获得本地遗忘模型。在本地遗忘过程中，VeriFed-UL 从一个受成员推断攻击（Membership Inference Attack, MIA）以及重训练模型在未见数据（即非训练数据）上的决策行为启发的全新视角来完成遗忘任务。具体而言，MIA 利用模型在成员数据与非成员数据上的行为差异来判断某个样本是否参与了模型训练；而重训练模型在预测未见数据的正确标签时通常表现出较低的置信度。基于这些观察，VeriFed-UL 引导目标车辆在全局模型的表示空间中进行重编码。具体策略是，利用由未见数据计算得出的各类别质心代表‘未被记忆的知识’，并将待遗忘数据强制对齐至最近的错误类别质心，从而直接净化其待遗忘数据的表示。通过设定明确的优化目标，VeriFed-UL 调整全局模型在待遗忘数据上的行为，使其与模型在未见数据上的行为不可区分。

此外，VeriFed-UL 不再对全局模型的全部参数进行优化，而是利用待遗忘数据在表示空间中进行有针对性的对齐，从而避免显著的性能退化。同时，VeriFed-UL 结合了基于目标车辆剩余数据的分类损失以及一个权重正则项，在迁移待遗忘数据表示的过程中进一步减轻对全局模型预测性能的负面影响。本文的主要贡献如下：
\begin{itemize}
\item 我们提出了 VeriFed-UL，一种面向 IoV 的实用且无需重训练的 FU 框架。该方法无需其他参与车辆进行大规模重训练，即可高效消除车辆指定数据对全局模型的影响，同时保留剩余的任务相关知识，以实现具有竞争力的预测性能。
\item 我们为 VeriFed-UL 设计了一种表示层级的本地遗忘策略，包含两个核心组件：目标导向的遗忘与模型性能修复。基于对比学习与 MIA 的再利用，所提出的目标导向遗忘组件使目标车辆能够将待遗忘数据的表示直接对齐至由非训练数据提取的最近错误类别质心，并与其原始表示分离，从而有效移除待遗忘数据的影响。从多任务学习的视角出发，模型性能修复组件通过在剩余数据上引入监督分类损失，并结合正则化项以最小化对未遗忘知识的干扰，在迁移待遗忘数据表示的同时保持全局模型的预测性能。
\item 我们在多种模型和数据集上对 VeriFed-UL 进行了系统性的实验评估。实验结果表明，VeriFed-UL 在无需耗时重训练的情况下实现了有效遗忘，并显著降低了全局模型在未遗忘数据上的预测性能退化。消融实验进一步验证了 VeriFed-UL 各组成部分的有效性与必要性。
\end{itemize}


\subsection{现有方法的局限性分析}
大多数主动式联邦遗忘（FU）方法通过对待遗忘数据集\(D_f\)的分类损失执行梯度上升（GA）来实现遗忘[21], [22], [23], [24]。然而，在某些遗忘场景中，梯度上升要么无法有效移除待遗忘数据，要么会导致灾难性遗忘。为评估GA的有效性，本文基于LOAN数据集构建了两个记忆强度不同的案例。图\ref{fig:f3-sys1}展示了首个目标车辆在不同案例下，模型$F(\omega^u)$的准确率变化。

本文通过后门攻击评估遗忘效果。通过强制全局模型记忆特定的后门模式，并将数值（即 10、80、20、100、20、100）分别赋值给特征索引（即 76、78、82、17、35、83），以构造高度可记忆的后门触发条件。在案例2中，将统一的数值（即 2）赋值给特征索引（即 76、77、78、82、83），用于在全局模型训练过程中模拟被遗忘数据所具有的一般性记忆强度。

在案例1（图\ref{fig:f3-sys1}(a)、\ref{fig:f3-sys1}(b)）中，当全局模型对\(D_f\)过拟合（分类损失趋近于0）时，反向梯度无法及时驱动参数更新以降低其在\(D_f\)上的准确率，导致遗忘不彻底。相反，案例2（图\ref{fig:f3-sys1}(c)、\ref{fig:f3-sys1}(d)）显示，梯度上升操作导致模型在\(D_t\)上的准确率大幅下降。这种性能下降源于对\(F(\omega^o)\)全部参数的无差别更新，以及梯度上升操作的发散特性——其目标是最大化而非最小化标准分类损失。
为此，我们将关注点从参数空间转移到全局模型的表示空间。具体而言，VeriFed-UL将全局模型解耦为表示提取器与分类器。通过对齐目标的指导，VeriFed-UL利用\(D_f\)优化表示提取器，从待遗忘数据的表示中有效识别并移除对分类最为关键的特征，从而实现有效遗忘。同时，该方法能相对完整地保留未遗忘数据的知识，避免模型性能大幅下降。
然而，利用\(D_f\)修改表示提取器存在两个核心挑战。首先，确定明确的遗忘目标作为指导信号，以主动移除待遗忘数据的记忆。其二，修改表示提取器可能会无意破坏剩余数据的表示。这种破坏可能导致其与分类器的错位，使最终的全局模型与原始全局模型大幅偏离，进而损害模型性能。

\begin{figure}[htb]
    \centering
    \includegraphics[scale=0.5]{picture/AccuracyOf.png}
    \caption{
        $F(\omega^u)$在数据集$D_f$和$D_t$上的准确率
    }
    \label{fig:f3-sys1}
\end{figure}
\subsection{全局模型表示行为的实证观察}
为确定有效遗忘的优化目标，我们首先观察训练后的全局模型\(F(\omega^o)\)与经过重训练的全局模型\(F(\bar{\omega})\)在待遗忘数据\(D_f\)和非成员数据\(D_t\)上的行为。图\ref{fig:f3-sys2}展示了\(F(\omega^o)\)与\(F(\bar{\omega})\)在不同数据上的交叉熵，可体现模型对数据的“记忆”能力[8]。\(F(\omega^o)\)与\(F(\bar{\omega})\)是通过FedAvg算法，基于CIFAR10数据集和ResNet18模型，由10辆车辆协同训练得到的。
（1）图\ref{fig:f3-sys2}(a)显示，由于\(D_f\)是\(F(\omega^o)\)的训练数据，该模型在\(D_f\)与\(D_t\)上的表现出不同的行为。
（2）图\ref{fig:f3-sys2}(a)还显示，受\(F(\omega^o)\)泛化能力的影响，\(D_t\)中的部分样本也会呈现较低的交叉熵。
（3）图\ref{fig:f3-sys2}(b)显示，由于\(D_f\)并非\(F(\bar{\omega})\)的训练数据，它在\(F(\bar{\omega})\)上的交叉熵更高。

\begin{figure}[htb]
    \centering
    \includegraphics[scale=0.9]{picture/CrossEntropy.png}
    \caption{
        $F(\omega_o)$ 与 $F(\bar{\omega})$ 在不同数据集上的交叉熵
    }
    \label{fig:f3-sys2}
\end{figure}

为进一步观察模型的决策行为，图\ref{fig:f3-sys3}通过t-SNE方法[36]，可视化了\(F(\omega^o)\)与\(F(\bar{\omega})\)生成的\(D_f\)和\(D_r\)的表示分布。
（1）图\ref{fig:f3-sys3}(a)显示，\(F(\omega^o)\)对训练数据标签的预测置信度较高，因其表示会聚类到对应类别中，类别间边界清晰。
（2）图\ref{fig:f3-sys3}(b)显示，\(F(\bar{\omega})\)无法高置信度地将\(D_f\)划分到特定类别。相反，\(D_f\)呈现分散分布，这表明\(D_f\)的决策边界已被破坏；其表示与不同类别的数据混杂，因此预测不确定性显著增加。

\begin{figure}[htb]
    \centering
    \includegraphics[scale=0.8]{picture/t-SNE.png}
    \caption{
        表示分布的 t-SNE 可视化结果
    }
    \label{fig:f3-sys3}
\end{figure}

\subsection{表示空间定向偏移的设计思想}
基于上述观察，VeriFed-UL通过设定明确的遗忘目标实现有效遗忘，将\(F(\omega^o)\)与\(D_f\)的关系从“已见”转变为“未见”，并模仿\(F(\bar{\omega})\)的决策行为。
一方面，VeriFed-UL更新\(F(\omega^o)\)，使生成的模型$\mathcal{F}(\omega^{\circ \prime})$在\(D_f\)上的行为，与其在未见数据上的行为无法区分，即\(F(D_f; \omega^{\circ \prime}) \approx F(D_t; \omega^{\circ \prime})\)。
由于在遗忘完成前无法获知$\mathcal{F}(\omega^{\circ \prime})$，我们让\(F(\omega^o)\)将\(D_f\)当作未见数据处理，并确保\(F(\omega^o)\)沿正确方向更新，以此近似得到$\mathcal{F}(\omega^{\circ \prime})$，即\(F(D_f; \omega^{\circ \prime}) ≈ F(D_t; \omega^o)\)。
另一方面，VeriFed-UL通过引导待遗忘数据的表征与表征空间中最近异类未见数据质心对齐，模拟\(F(\bar{\omega})\)的决策行为，进一步放大\(D_f\)的预测不确定性。VeriFed-UL迫使待遗忘数据的表示脱离其实际类别，与这些质心的表示混淆。这种分布上的偏移让$\mathcal{F}(\omega^{\circ \prime})$无法清晰识别\(D_f\)的表示，在不显著降低模型整体预测性能的前提下，提升了预测不确定性与遗忘效果。该方法符合对比学习（CL）的原理。但本文采用模型级对比学习，用于表示层面的遗忘，这与上述观察直接对应。
具体而言，VeriFed-UL通过新颖的正负样本对设计，从已训练的全局模型中移除待遗忘数据的影响，从而适配模型级对比学习以实现有效遗忘。此外，由于目标车辆可访问其剩余数据与原始全局模型，VeriFed-UL将分类损失与权重正则项结合，以缓解第二个挑战，进一步降低调整\(D_f\)表示时对全局模型预测性能的负面影响。
